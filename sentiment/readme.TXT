1. func.py是我的微博文本情感分类代码文件，另外的wiki_zh.py和langconv.py是github上开源的简繁体转化代码
2. 执行时使用的数据集文件是被我修改过百余条标签值后的train_fixed.csv文件，具体修改标准和修改清单可见报告
3. 将train_fixed.csv内的数据划分为9:1的训练集和测试集。
4. addWords.TXT是针对结巴分词的自定义新增词汇
5. key.csv是针对训练集生成的关键词列表，第一列是词语本身序号，第二列是与近邻差异度相似的词语合并后的所在集合的序号，第三列是该词中立条件概率与消极条件概率之比（正时中立条件概率为分子，负时消极条件概率为分子），第四列与第三列类似，是该词积极概率与消极条件概率之比。该词表筛除了本身条件频率过小者和两个比值相差过小者，一般会含有7000左右的词汇和3000左右的集合
6. 最终的分类结果是testResult.csv
7. 程序运行在分词和向量化阶段较慢，需要十来分钟